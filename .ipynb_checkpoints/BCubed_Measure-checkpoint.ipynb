{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to evaluate text clustering algorithms with BCubed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The B-cubed method is described in detail in:\n",
    "\n",
    "[1] Bagga, Amit and Breck Baldwin. 1998. Algorithms for scoring coreference chains. In Proceedings of the First International Conference on Language Resources and Evaluation Workshop on Linguistic Coreference.\n",
    "\n",
    "The examples are taken from this paper:\n",
    "\n",
    "[2] Amigó, E., Gonzalo, J., Artiles, J. et al. A comparison of extrinsic clustering evaluation metrics based on formal constraints. Inf Retrieval 12, 461–486 (2009). https://doi.org/10.1007/s10791-008-9066-8\n",
    "\n",
    "In the paper the authors analyzed a wide range of metrics and showed that only BCubed satisfies all formal constraints. However, it is not suitable for overlapping clustering evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is BCubed Precision and BCubed Recall calculated?\n",
    "\n",
    "Precision represents how many items in the same cluster belong to its category. \n",
    "The Recall associated to one item represents how many items from its category appear in its cluster. [2]\n",
    "\n",
    "<img src=\"1.jpg\">\n",
    "\n",
    "## How to interpret Precision and Recall in BCubed? \n",
    "\n",
    "High BCubed __Recall__: Most related items are in a cluster\n",
    "\n",
    "High BCubed __Precision__: No noisy items in a cluster [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to easy calculate Precision and Recall?\n",
    "\n",
    "$$Recall (R) = \\frac{\\text{number of correct elements in the cluster}^{2}}{\\text{number of these elements in all clusters}}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Precision (P) = \\frac{\\text{number of correct elements in the cluster}^{2}}{\\text{number of elements in the cluster}}$$ \n",
    "\n",
    "$$F(BCubed) = \\frac{2 * P * R}{P + R}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's calculate the following (left clustered) example [2]\n",
    "\n",
    "<img src=\"3.png\" width=\"200\">\n",
    "\n",
    "$$Recall (R) = \\frac{\\frac{4*4}{5} + \\frac{1}{5}+ \\frac{2*2}{6}+ \\frac{3*1}{1}+ \\frac{4*4}{6}} {14} = 0.69$$\n",
    "\n",
    "\n",
    "$$Precision (P) = \\frac{\\frac{4*4}{4} + \\frac{1}{3}+ \\frac{2*2}{3}+ \\frac{3*1}{7}+ \\frac{4*4}{7}}{14} = 0.59 $$\n",
    "\n",
    "$$F(BCubed) = \\frac{2 * 0.69 * 0.59}{0.69 + 0.59} = 0.63$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use BCubed in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bcubed\n",
      "  Downloading bcubed-1.5-py2.py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\global-environment\\lib\\site-packages (from bcubed) (1.18.0)\n",
      "Installing collected packages: bcubed\n",
      "Successfully installed bcubed-1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bcubed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcubed\n",
    "\n",
    "\"\"\"\n",
    "   Compute Bcubed Precision, Recall and F-Score \n",
    "   clustering_dict: dictionary representing clustering output\n",
    "   gold_standard_dict: ground-truth dictionary\n",
    "   Dictionary Format: {item: clusters}\n",
    "\"\"\"\n",
    "\n",
    "def bcubed_compute(clustering_dict, gold_standard_dict):\n",
    "    precision = bcubed.precision(clustering_dict, gold_standard_dict)\n",
    "    recall = bcubed.recall(clustering_dict, gold_standard_dict)\n",
    "    fscore = bcubed.fscore(precision, recall)\n",
    "    print(\"Precision={:.2f}, Recall={:.2f}, F_BCubed={:.2f}\".format(precision, recall, fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=1.00, Recall=0.62, F_BCubed=0.77\n"
     ]
    }
   ],
   "source": [
    "# example ground-truth data\n",
    "ground_truth = {\n",
    "    \"item1\": set([\"black\", \"gray\"]),\n",
    "    \"item2\": set([\"black\", \"gray\"]),\n",
    "    \"item3\": set([\"blue\"]),\n",
    "    \"item4\": set([\"dashed\"]),\n",
    "}\n",
    "\n",
    "# example clustering \n",
    "clustering = {\n",
    "    \"item1\": set([\"black\"]),\n",
    "    \"item2\": set([\"gray\"]),\n",
    "    \"item3\": set([\"blue\"]),\n",
    "    \"item4\": set([\"dashed\"]),\n",
    "}\n",
    "\n",
    "bcubed_compute(clustering, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to implement BCubed extended version in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "\"\"\"Computes multiplicity Precision for two items.\"\"\"\n",
    "def mult_precision(item1, item2, clustering, ground_truth):    \n",
    "    return min(len(clustering[item1] & clustering[item2]), len(ground_truth[item1] & ground_truth[item2])) \\\n",
    "        / float(len(clustering[item1] & clustering[item2]))\n",
    "\n",
    "\"\"\"Computes the multiplicity Recall for two items.\"\"\"\n",
    "def mult_recall(item1, item2, clustering, ground_truth):\n",
    "    \n",
    "    return min(len(clustering[item1] & clustering[item2]), len(ground_truth[item1] & ground_truth[item2])) \\\n",
    "        / float(len(ground_truth[item1] & ground_truth[item2]))\n",
    "\n",
    "\n",
    "\"\"\"Computes overall extended BCubed Precision for the Clustering and ground-truth\"\"\"\n",
    "def extended_precision_bcubed(clustering, ground_truth):    \n",
    "    return numpy.mean([numpy.mean([mult_precision(item1, item2, clustering, ground_truth) \\\n",
    "        for item2 in clustering if clustering[item1] & clustering[item2]]) for item1 in clustering])\n",
    "\n",
    "\"\"\"Computes overall extended BCubed Recall for the Clustering and ground-truth\"\"\"\n",
    "def extended_recall_bcubed(clustering, ground_truth):\n",
    "    return numpy.mean([numpy.mean([mult_recall(item1, item2, clustering, ground_truth) \\\n",
    "        for item2 in clustering if ground_truth[item1] & ground_truth[item2]]) for item1 in clustering])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended Precision=1.00, Extended Recall=0.62\n"
     ]
    }
   ],
   "source": [
    "print(\"Extended Precision={:.2f}, Extended Recall={:.2f}\".format(extended_precision_bcubed(clustering, ground_truth), extended_recall_bcubed(clustering, ground_truth)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to calculate BCubed extended? --> see B-Cubed_Extended_Calculationc.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:\n",
    "\n",
    "http://e-spacio.uned.es/fez/eserv/bibliuned:DptoLSI-ETSI-MA2VICMR-1090/Documento.pdf\n",
    "\n",
    "http://www.cs.cmu.edu/~yimengz/papers/Coreference_survey.pdf\n",
    "\n",
    "https://www.uni-weimar.de/medien/webis/events/pan-16/pan16-papers-final/pan16-author-identification/sari16-notebook.pdf \n",
    "\n",
    "The python implementation is based on: https://github.com/hhromic/python-bcubed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
